diff --git a/CMakeLists.txt b/CMakeLists.txt
index f40cf7738..bd6599c9f 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -147,10 +147,10 @@ if(NOT MSVC)
 
   # clang outputs some warnings for unknown flags that are not caught by check_cxx_compiler_flag
   # adding -Werror turns such warnings into errors
-  check_cxx_compiler_flag("-Werror" COMPILER_SUPPORT_WERROR)
-  if(COMPILER_SUPPORT_WERROR)
-    set(CMAKE_REQUIRED_FLAGS "-Werror")
-  endif()
+  #check_cxx_compiler_flag("-Werror" COMPILER_SUPPORT_WERROR)
+  #if(COMPILER_SUPPORT_WERROR)
+  #  set(CMAKE_REQUIRED_FLAGS "-Werror")
+  #endif()
   ei_add_cxx_compiler_flag("-pedantic")
   ei_add_cxx_compiler_flag("-Wall")
   ei_add_cxx_compiler_flag("-Wextra")
diff --git a/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h b/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h
index 21be6ea42..7464ee56a 100644
--- a/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h
+++ b/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h
@@ -1006,7 +1006,7 @@ struct TensorEvaluator<const TensorContractionOp<Indices, LeftArgType, RightArgT
       } else {
         eigen_assert(!use_thread_local);
         device_.enqueueNoNotification(
-            [=]() { kernel(m, n, k, use_thread_local); });
+            [=, this]() { kernel(m, n, k, use_thread_local); });
       }
     }
 
@@ -1060,7 +1060,7 @@ struct TensorEvaluator<const TensorContractionOp<Indices, LeftArgType, RightArgT
         while (end - start > 1) {
           Index mid = (start + end) / 2;
           device_.enqueueNoNotification(
-              [=]() { enqueue_packing_helper(mid, end, k, rhs); });
+              [=, this]() { enqueue_packing_helper(mid, end, k, rhs); });
           end = mid;
         }
 
@@ -1079,7 +1079,7 @@ struct TensorEvaluator<const TensorContractionOp<Indices, LeftArgType, RightArgT
 
         if (pack_async) {
           device_.enqueueNoNotification(
-              [=]() { enqueue_packing_helper(start, end, k, rhs); });
+              [=, this]() { enqueue_packing_helper(start, end, k, rhs); });
         } else {
           enqueue_packing_helper(start, end, k, rhs);
         }
diff --git a/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h b/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h
index e524b535a..3acabc40f 100644
--- a/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h
+++ b/unsupported/Eigen/CXX11/src/Tensor/TensorDeviceThreadPool.h
@@ -207,12 +207,12 @@ struct ThreadPoolDevice {
     // block_count leaves that do actual computations.
     Barrier barrier(static_cast<unsigned int>(block.count));
     std::function<void(Index, Index)> handleRange;
-    handleRange = [=, &handleRange, &barrier, &f](Index firstIdx,
+    handleRange = [=, this, &handleRange, &barrier, &f](Index firstIdx,
                                                   Index lastIdx) {
       while (lastIdx - firstIdx > block.size) {
         // Split into halves and schedule the second half on a different thread.
         const Index midIdx = firstIdx + divup((lastIdx - firstIdx) / 2, block.size) * block.size;
-        pool_->Schedule([=, &handleRange]() { handleRange(midIdx, lastIdx); });
+        pool_->Schedule([=, this, &handleRange]() { handleRange(midIdx, lastIdx); });
         lastIdx = midIdx;
       }
       // Single block or less, execute directly.
